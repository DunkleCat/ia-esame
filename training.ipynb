{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "addestramento-v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/DunkleCat/ia-esame/blob/master/training.ipynb",
      "authorship_tag": "ABX9TyPVshBUH4qlkp7IKQdW0qfV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjbOOAFTfG-f"
      },
      "source": [
        "# !pip install -r requirements.txt"
      ],
      "execution_count": 487,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbnDWeBAhNZU"
      },
      "source": [
        "# Caricamento del dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGwiLbchbJ6g"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def io_load_multiple_csv(csv_path_list):\n",
        "  dataframe_list = []\n",
        "  for elem in csv_path_list:\n",
        "    dataframe_list.append(io_load_csv(elem))\n",
        "  return dataframe_list\n",
        "\n",
        "def io_load_csv(csv_path):\n",
        "  return pd.read_csv(csv_path)  "
      ],
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqaGCvdyhVGY"
      },
      "source": [
        "# Analisi del Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ENAcUFdkRPM"
      },
      "source": [
        "## Normalizzazione valori nulli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abfKiypPh7kW"
      },
      "source": [
        "Come primo passaggio normalizziamo i valori che rappresentano attributi mancanti trasformandoli tutti in np.nan\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoNYh4_miEiI"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize_nan(dataframe, nan_list):\n",
        "  for elem in nan_list:\n",
        "    dataframe.replace(elem, np.nan, inplace=True)\n",
        "  return dataframe"
      ],
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ftIA-IkVeG"
      },
      "source": [
        "## Analisi dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqdINduvkkh6"
      },
      "source": [
        "Passiamo ora ad analizzare i dati in ingresso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZaFwM8jhcUE"
      },
      "source": [
        "def print_infos(dataframe):\n",
        "  print(\"Dataframe miscellaneous:\\n\")\n",
        "  print(\"Rows     : {}\".format(dataframe.shape[0]) )\n",
        "  print(\"Columns  : {}\".format(dataframe.shape[1]))\n",
        "  print(\"\\nFeatures :\\n{}\".format(dataframe.columns.tolist()))\n",
        "  print(\"\\nUnique values :\\n{}\".format(dataframe.nunique()))\n",
        "\n",
        "  print(\"\\nDataframe info:\")\n",
        "  dataframe.info()\n",
        "\n",
        "  for elem in dataframe:\n",
        "    print(elem, ': ', np.sort(dataframe[elem].unique()))"
      ],
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWbBWC5Zk_Gk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "# def print_feature_plots(dataframe, feature_list, feature_target):\n",
        "#   for elem in dataframe:\n",
        "#     if elem in feature_list:\n",
        "#       plot = sb.catplot(x = feature_target, \n",
        "#                         col = elem, \n",
        "#                         data = dataframe, \n",
        "#                         kind = 'count')\n",
        "#     plt.show()\n",
        "\n",
        "def print_feature_plots(dataframe, feature_target):\n",
        "  categorical_features = get_categorical_features(dataframe)\n",
        "  print(categorical_features)\n",
        "  numeric_features = get_numeric_features(dataframe)\n",
        "  print(numeric_features)\n",
        "  for elem in dataframe:\n",
        "    if elem in categorical_features:\n",
        "      print(\"Categorical:\")\n",
        "      plot = sb.catplot(x = feature_target, \n",
        "                        col = elem, \n",
        "                        data = dataframe, \n",
        "                        kind = 'count')\n",
        "    elif elem in numeric_features:\n",
        "      print(\"Numeric:\")\n",
        "      plot = sb.displot(data = dataframe,\n",
        "                        x = elem,\n",
        "                        hue = feature_target) \n",
        "  \n",
        "    plt.show()"
      ],
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifQnmcdEF-ns"
      },
      "source": [
        "Dati un dataframe ed una lista di feature elimina dal dataframe tutte le features presenti all'interno della lista. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EouVsndIqn4U"
      },
      "source": [
        "def clean_useless(dataframe, column_list):\n",
        "  for elem in column_list:\n",
        "    dataframe.pop(elem)\n",
        "  return dataframe"
      ],
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxvzyeTI4hiU"
      },
      "source": [
        "# Modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiirmBL-lr4u"
      },
      "source": [
        "Vengono sfruttate le possiilità offerte da una pipeline di sklearn per creare ed utilizzare il modello.\n",
        "\n",
        "Come classificatore viene utilizzato l'algoritmo di Random Forest. Esso è un algoritmo di tipo Ensemble, e quindi sfrutta la combinazione di altri algoritmi più deboli ma opportunamente organizzati ed utilizzati per ottenere dei risultati soddisfacenti. Nel caso specifico abbiamo una combinazione di classificatori di tipo Decision tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8zabkrb4pKS"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def create_model(dataframe):\n",
        "\n",
        "  preprocessor = create_preprocessor(dataframe)\n",
        "\n",
        "  return Pipeline(\n",
        "      steps = [('preprocessor', preprocessor),\n",
        "               ('classifier', RandomForestClassifier())])\n",
        "\n",
        "def create_preprocessor(dataframe):\n",
        "  numeric_features = get_numeric_features(dataframe)\n",
        "  numeric_transformer = Pipeline(\n",
        "      steps = [('imputer', SimpleImputer(strategy='median')),\n",
        "               ('scaler', StandardScaler())])\n",
        "\n",
        "  categorical_features = get_categorical_features(dataframe)\n",
        "  categorical_transformer = Pipeline(\n",
        "      steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "             ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "  return ColumnTransformer(\n",
        "      transformers=[('num', numeric_transformer, numeric_features),\n",
        "                    ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "def get_numeric_features(dataframe):\n",
        "  numeric_features = []\n",
        "  for elem in dataframe:\n",
        "    if is_numeric(dataframe[elem][0]):\n",
        "      numeric_features.append(elem)\n",
        "  return numeric_features\n",
        "\n",
        "def get_categorical_features(dataframe):\n",
        "  categorical_features = []\n",
        "  for elem in dataframe:\n",
        "    if is_categorical(dataframe[elem][0]):\n",
        "      categorical_features.append(elem)\n",
        "  return categorical_features\n",
        "\n",
        "def is_numeric(elem):\n",
        "  return not is_categorical(elem)\n",
        "\n",
        "def is_categorical(elem):\n",
        "  return type(elem) is str"
      ],
      "execution_count": 494,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXh8lGdu4xh4"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def train_model(model, dataframe_train, dataframe_train_target):\n",
        "  model.fit(dataframe_train, dataframe_train_target)\n",
        "  print('Training score: {}'.format(model.score(dataframe_train, dataframe_train_target)))\n",
        "  return model"
      ],
      "execution_count": 495,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mtvuGE95XgY"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def print_test_model(model, dataframe_test, dataframe_test_target):\n",
        "  preds = model.predict(dataframe_test)\n",
        "  print('Test score: {}'.format(model.score(dataframe_test, dataframe_test_target)))\n",
        "  print(classification_report(dataframe_test_target, preds))"
      ],
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-AuOESg-WQJ"
      },
      "source": [
        "# Preparazione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScYNIn3y-a3R"
      },
      "source": [
        "## LIBRARIES ###################################################################\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "################################################################################\n",
        "\n",
        "## FUNCTIONS ###################################################################\n",
        "\n",
        "def io_load_csv(csv_path):\n",
        "  return pd.read_csv(csv_path)\n",
        "\n",
        "def split_train_test(dataframe):\n",
        "  train, test = train_test_split(dataframe, test_size=0.2)\n",
        "  train.name, test.name = 'train', 'test'\n",
        "  return train, test\n",
        "\n",
        "def io_save_dataframe_to_file(dataframe):\n",
        "  dataframe.to_csv(dataframe.name + \".csv\", index=False)\n",
        "\n",
        "def io_save_multiple_dataframes_to_file(dataframe_list):\n",
        "  list(map(io_save_dataframe_to_file, dataframe_list))\n",
        "\n",
        "################################################################################\n",
        "\n",
        "## MANUAL INTERVENTION #########################################################\n",
        "\n",
        "csv_path = \"./dataset.csv\"\n",
        "\n",
        "################################################################################\n",
        "\n",
        "## EXECUTION ###################################################################\n",
        "\n",
        "dataframe = io_load_csv(csv_path)\n",
        "\n",
        "dataframe_list = split_train_test(dataframe)\n",
        "io_save_multiple_dataframes_to_file(dataframe_list)\n",
        "\n",
        "################################################################################"
      ],
      "execution_count": 497,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvabuvzMijfD"
      },
      "source": [
        "# Esecuzione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr1o_OB9ik78"
      },
      "source": [
        "## MISCELLANEOUS ###############################################################\n",
        "\n",
        "# Readable float \n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "################################################################################"
      ],
      "execution_count": 498,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJhX6GtOgbiA"
      },
      "source": [
        "## MANUAL INTERVENTION #########################################################\n",
        "\n",
        "dataframe_train_path = \"train.csv\"\n",
        "dataframe_test_path = \"test.csv\"\n",
        "\n",
        "################################################################################\n",
        "\n",
        "## EXECUTION ###################################################################\n",
        "\n",
        "dataframe_train, dataframe_test = io_load_multiple_csv([dataframe_train_path, \n",
        "                                                        dataframe_test_path])\n",
        "\n",
        "################################################################################"
      ],
      "execution_count": 499,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDPjs4TCx9sa"
      },
      "source": [
        "dataframe_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuM7YKJ2FFHO"
      },
      "source": [
        "## MANUAL INTERVENTION #########################################################\n",
        "\n",
        "nan_list = [\n",
        "            \"\", \n",
        "            \" \", \n",
        "            \"?\",\n",
        "            \"unknown\"\n",
        "] # All the ways a nan element appears inside the dataframe\n",
        "\n",
        "feature_target = \"\"\n",
        "\n",
        "################################################################################\n",
        "\n",
        "## EXECUTION ###################################################################\n",
        "\n",
        "# Clean the dataframe from nan values\n",
        "dataframe_train = normalize_nan(dataframe_train, nan_list)\n",
        "dataframe_test = normalize_nan(dataframe_test, nan_list)\n",
        "\n",
        "# Print dataframe's infographic\n",
        "print_infos(dataframe_train)\n",
        "\n",
        "print_feature_plots(dataframe_train, feature_target)\n",
        "\n",
        "################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YwnlUJUF2yP"
      },
      "source": [
        "## MANUAL INTERVENTION #########################################################\n",
        "\n",
        "useless_list = [\n",
        "                # \"salary\"  \n",
        "                # \"ScheduledDay\"     \n",
        "] # All the meaningless attributes in relation to the prediction \n",
        "\n",
        "################################################################################\n",
        "\n",
        "## EXECUTION ###################################################################\n",
        "\n",
        "# Clean the dataframe from meningless features\n",
        "dataframe_train = clean_useless(dataframe_train, useless_list)\n",
        "dataframe_test = clean_useless(dataframe_test, useless_list)\n",
        "\n",
        "# Add some useful features\n",
        "# dataframe_train = add_diffence_scheduled_appointment_day(dataframe_train)\n",
        "# dataframe_test = add_diffence_scheduled_appointment_day(dataframe_test)\n",
        "\n",
        "################################################################################\n"
      ],
      "execution_count": 503,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVf94hWA3yEA"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## TARGET PREPARATION ##########################################################\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "dataframe_train_target = le.fit_transform(dataframe_train.pop(feature_target))\n",
        "dataframe_test_target = le.transform(dataframe_test.pop(feature_target))\n",
        "\n",
        "################################################################################"
      ],
      "execution_count": 504,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYkMADTVMvi6"
      },
      "source": [
        "## CLASSIFIER ##################################################################\n",
        "\n",
        "# Create the classifier\n",
        "classifier = create_model(dataframe_train)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = train_model(classifier, dataframe_train, dataframe_train_target)\n",
        "\n",
        "# Test the classifier\n",
        "print_test_model(classifier, dataframe_test, dataframe_test_target)\n",
        "\n",
        "################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}